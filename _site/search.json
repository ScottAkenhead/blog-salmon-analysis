[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Context! What’s Happening?",
    "section": "",
    "text": "x <- 1 + 1\ncat('x =', x, '\\n')\n\nx = 2 \n\n\n\n\n\nThis is the caption to the figure. The figure is a link.\n\n\nI put a pencil in my hair.\nIt fell to earth I know not where.\nI put a pencil, yea, chest high,\nI haven’t see it since July.\nI ask you, what do you think of that?\nI guess it proves I’m bald and fat."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "",
    "text": "My first post via Quarto blog, please forebear.\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/welcome/index.html#area-under-the-curve-auc",
    "href": "posts/welcome/index.html#area-under-the-curve-auc",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Area Under the Curve (AUC)",
    "text": "Area Under the Curve (AUC)\nConvention determines salmon spawner abundance by linear interpolation between survey estimates each year separately, with assumptions about timing for zero abundance before and after the surveys: a trapezoid (Parken, Bailey, and Irvine 2003). There is an alternative, where all years are combined to\n\ndetermine the general temporal pattern of spawner abundance (“salmon days), perhaps Gaussian if early arrivals and late survivors viewed as simply rare, perhaps Beta if ordained zero.\ngiven (a), estimate the change to that shape for each year, perhaps skewed to be earlier or later than the pattern across all years,\ngiven (a) and (b), determine the total abundance for each year, and\nfrom (a), (b), and (c), determine the observation error for individual surveys, \\(\\sigma_{obs},\\) perhaps as a fixed percentage error (\\(\\sigma_{obs}=20\\%\\) of true abundance, implying a log transform) rather than an absolute error (\\(\\sigma_{obs} = 20\\) spawners)."
  },
  {
    "objectID": "posts/welcome/index.html#test-dataset",
    "href": "posts/welcome/index.html#test-dataset",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Test Dataset",
    "text": "Test Dataset\nAs test data, the abundance estimates for 21 surveys over 4 years from Parken et al. 2003 (Figure 1). The numbers are reproduced only approximately (Table 1), and plotted in Figure 2 with the observations from all years combined.\n\n\n\nFigure 1: Plot of trapezoids from salmon spawner surveys from Parken et al (2003).\n\n\n\ndat <- data.frame(\n    year=c(rep(1996,5),rep(1997,5),rep(1998,6),rep(1999,5)), \n    day=c(5,9,13,18,23,  5,9,13,15,19,  5,9,13,15,19,23,  5,9,13,15,19),\n    count=c(850,6000,11000,5000,1000,  500,2700,4000,4100,2500,\n            15,40,200,500,700,600,  500,2500,4100,4000,1300) )\nkbl(dat)\n\n\n\nTable 1:  Salmon counts as read from Parken et al. (2003). \n \n  \n    year \n    day \n    count \n  \n \n\n  \n    1996 \n    5 \n    850 \n  \n  \n    1996 \n    9 \n    6000 \n  \n  \n    1996 \n    13 \n    11000 \n  \n  \n    1996 \n    18 \n    5000 \n  \n  \n    1996 \n    23 \n    1000 \n  \n  \n    1997 \n    5 \n    500 \n  \n  \n    1997 \n    9 \n    2700 \n  \n  \n    1997 \n    13 \n    4000 \n  \n  \n    1997 \n    15 \n    4100 \n  \n  \n    1997 \n    19 \n    2500 \n  \n  \n    1998 \n    5 \n    15 \n  \n  \n    1998 \n    9 \n    40 \n  \n  \n    1998 \n    13 \n    200 \n  \n  \n    1998 \n    15 \n    500 \n  \n  \n    1998 \n    19 \n    700 \n  \n  \n    1998 \n    23 \n    600 \n  \n  \n    1999 \n    5 \n    500 \n  \n  \n    1999 \n    9 \n    2500 \n  \n  \n    1999 \n    13 \n    4100 \n  \n  \n    1999 \n    15 \n    4000 \n  \n  \n    1999 \n    19 \n    1300 \n  \n\n\n\n\n\n\n\nSetPar()\nplot(dat$day, 0.001*dat$count, xlim=c(0,36),ylim=c(0,12),yaxs=\"i\",\n     xlab='Day from 31 October', ylab=\"Salmon Count ('000)\")\nAxis34()\n\n\n\n\nFigure 2: Salmon counts as read from Parken et al. (2003) by day with all years combined.\n\n\n\n\n\nScale by Maximum Count\nFirst guess at shape is to scale observations by maximum each year, then fit a loess curve (Figure 3). It is necessary to sort the data by day for loess. Zeros were added outside the dates of observations, as per using a trapezoid.\n\nxa <- by(dat$count,dat$year, max) # get maximums by year\nxb <- by(dat$count,dat$year, length) # number of observations by year\n# one value per year, copy for each obs in a year.\nxc <- NULL  # temporary\nfor(j in 1:4) xc <- c(xc,rep( xa[[j]], xb[[j]]) )    \ndat$max <- xc \ndat$scaled <- dat$count / dat$max\nxa <- dat[order(dat$day), c(\"day\",\"scaled\")] # extract and sort\nlo <- loess(scaled ~ day, data=xa) # fit smoother to sorted data\n#  range for resulting smooth line is range of observed days\ndays = 5:23\nloPred <- predict(lo, data.frame(day = days) ) # all days in range\nloPred <-data.frame(pred=loPred,day=days)      # not just observed day\n\nSetPar()\nplot(scaled~day,data=xa, xlim=c(0,36),\n     xlab='Day from 31 October', ylab='Scaled Count')\nlines(loPred$pred  ~ loPred$day ) \nAxis34()\n\n\n\n\nFigure 3: Salmon counts scaled (from 0 to 1) by the maximum count each year."
  },
  {
    "objectID": "posts/welcome/index.html#shift-observations-by-day-of-maximum",
    "href": "posts/welcome/index.html#shift-observations-by-day-of-maximum",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Shift Observations by Day of Maximum",
    "text": "Shift Observations by Day of Maximum\nOne of the years has a large change in timing, adding scatter to the preceding plot. We can reduce that scatter shifting (aligning) observations according to date of maximum abundance within years (Figure 4). This is inaccurate (a hueristic) but demonstrates a parameter (timing) that will be estimated better subsequently. The variable shift is the shifted value for day of observation, with negative values and the peak will be at day shift. Apply the shift and plot.\n\npeak <-dat$day[ which(dat$count == dat$max)] # peak day by year \nxa <- NULL # temporary\nfor(j in 1:4) xa <- c(xa,rep( peak[j], xb[[j]]) )    \ndat$shift <- dat$day - xa \nxa <- dat[order(dat$shift), c(\"shift\",\"scaled\")] # extract and sort\n# add zeros outside range of obs.\nxa0 <- rbind (c(-15,0), xa, c(15,0))\nlo <- loess(scaled ~ shift, data=xa0) # smoother #,span=0.5)\nloPred <- predict(lo, data.frame(shift= -15:15) )\nloPred <-data.frame(pred=loPred,shift=c(-15:15))\n# redo preceding plot\nSetPar()\nplot(scaled~shift,data=xa0, xlim=c(-18,18), ylim=c(0,1), yaxs=\"i\",\n     xlab='Day from Year Peak', ylab='Scaled Count')\nlines(pred ~shift, data = loPred ) # \nAxis34()\n\n\n\n\nFigure 4: Salmon counts shifted and scaled (from 0 to 1) by the maximum count, and the corresponding day, within each year."
  },
  {
    "objectID": "posts/welcome/index.html#assume-gaussian",
    "href": "posts/welcome/index.html#assume-gaussian",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Assume Gaussian",
    "text": "Assume Gaussian\nFigure 4 suggests a symmetric Gaussian (“normal”) probability density distribution (PDD):\n\\[ \\textbf{G}(x) = (2\\pi \\sigma)^{-1/2} ~ e^{ -(x-\\mu)^2 /2\\sigma ^2} \\]\nwith \\(\\mu \\approx 0 \\text{ and } \\sigma \\approx 5\\) days as noticed from crude scaling of abundance and shifting of time for each year.\nAs well as the parameters \\(\\mu\\)  and \\(\\sigma,\\) additional parameter \\(\\eta\\) is required for total abundance, the integral of the PDD and proportional to maximum abundance.\nThe integral of the Gauss-Laplace function \\[\\int{e^{-x^2}} = (2\\pi)^{1/2} \\approx 2.5\\] For a PDD, the integral must be 1, and this is effected by the term \\((2\\pi \\sigma )^{-1/2} \\approx 0.4.\\) This is the maximum of the Gaussian PDD at \\(\\mu = 0\\) when \\(\\sigma = 1.\\) If the abundance \\(\\eta= 1/0.3989422804 = 2.505528\\) then the maximum for the curve is 1 and the integral \\(\\approx 2.5.\\) Similarly, when \\(\\sigma = 2\\) the maximum is 1 when \\(\\eta= 2/0.4 = 5\\) and for \\(\\sigma = 5, ~ \\eta=12.5\\)\nIn the scaled and shifted data the maximum was assigned to be 1 and it was observed that \\(\\sigma \\approx 5.\\) Fitting a Gaussian distribution with 3 parameters \\((\\eta,\\mu,\\sigma)\\) to all years combined, and after the rough scaling and shifting, is accomplished by the following chunk.\nThis chunk is a non-linear fit, obtained by searching for the parameters that have the lowest SSQ, the lowest sum of squared differences between observed and predicted (fitted) values. A function Gssq() is defined for this; it uses the built-in function stats::dnorm (normal probability density) to predict \\(\\hat{y}\\) for each observed day, given trial estimates for \\(\\mu,~ \\sigma,~ \\eta\\) and determines the SSQ. Then Gssq() is a parameter for the built-in function stats::optim that searches for value of the parameters that minimize SSQ. The other parameters for optim() are (1) a starting guess at parameters, and (2) the observed data: 21 values of day and abundance.\nFitting is by searching for the set of parameters that minimizes the sum of squared differnces (SSQ) between predicted \\(\\hat{y}\\) and observed \\(y\\), \\[ SSQ = \\sum{(y - \\hat{y})^2}\\]\nGiven the SSQ at best fit, we can determine how well the data is fitted by a Gaussian, \\(\\hat{y},\\) compared to fitting the mean abundance over all days, \\(\\bar{y},\\) a default model, by determining the reduction in SSQ: \\[ r^2 = 1- \\frac{\\sum (y-\\hat{y})^2}{\\sum (y-\\bar{y})^2 }.\\]\n\nGssq <- function(par, xy){\n    x <- xy[,1]; y<-  xy[,2];\n    eta <- par[1]; mu <- par[2]; sigma <- par[3];\n    ybar <- eta * dnorm(x,mu,sigma)\n    ssq <- sum( (y-ybar)^2)\n    return(ssq)\n}\nGfit <- optim(par=c(12.5, 0, 5), Gssq, xy=xa )\npar = Gfit$par; pr = round(par,2)\nSSQ <- sum( (xa[,2] - mean(xa[,2]))^2 ) # sum of y minus y-hat, squared\nr2 <- round (1- Gfit$value/SSQ, 2) # Gfit$value is SSQ fitted. \ncat('r^2 = ', r2, ', eta = ',pr[1], ', mu = ',pr[2],\n    ', sigma = ', pr[3], '\\n', sep='')\nr^2 = 0.94, eta = 11.02, mu = 0.05, sigma = 4.29\n\nThe result provides \\(\\sigma \\approx 4.3\\) which is a more narrow spread than noticing the inflection point in the Gaussian, at \\((1 ~\\sigma),\\) was about \\(\\pm5\\) from the mean. The fitted maximum will necessarily be close to 1 because of our scaling, but in this case greater than 1, given \\(\\sigma / 0.4 = 10.72\\) but \\(\\eta = 11.2,\\) due to our rough scaling.\nThe fitted line is compared visually to the data by the following chunk. A smooth Gaussian curve is plotted by estimating a value for 18 days before and after the mean day.\n\nx <- c(-18:18) # 37 points for a smooth(er) line.\npred <- par[1] * dnorm(x, par[2],par[3]) # eta, mu, sigma\nSetPar()\nplot(scaled~shift,data=xa, xlim=c(-18,18), ylim=c(0,1.2),yaxs=\"i\",\n     xlab='Day from Annual Peak', ylab='Scaled Count')\nlines(pred ~ x)\nAxis34()\n\n\n\n\nFigure 5: Gaussian probability density fitted to the scaled and shifted counts."
  },
  {
    "objectID": "posts/welcome/index.html#year-effects",
    "href": "posts/welcome/index.html#year-effects",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Year Effects",
    "text": "Year Effects\nThe preceding identified the overall pattern as Gaussian with \\(\\sigma \\approx 4.3.\\) If \\(\\sigma\\) is assumed to be constant across years, as Figure 5 suggests, then only two observations per year are required to estimate total abundance: \\(\\eta_t,~ \\mu_t.\\) To clarify: a single observation of early and small abundance cannot distinguish a small run with average timing from a big run that is late; one subsequent observation can (in theory).\nThis test dataset has 5 or 6 observations per year, so precision is improved and over-fitting is reduced compared to (a) fitting 3 parameters to each year separately, or (b) interpolating a trapezoid that includes arbitrarily placed zeros.\nThe next step estimates 8 parameters for year effects: \\(\\eta\\) (abundance) and \\(\\mu\\) (timing) for each of 4 years, and 1 estimate for \\(\\sigma\\) (spread) from 21 observations. The ratio of \\(2.\\bar{3}\\) data points to parameters might be improved by adding more years: 20 years @ 5 surveys/year would be \\(11.\\bar{1}.\\)\n\\[\\hat{y}_{day, year} = \\eta_{year} ~ \\textbf{G}(x_{year},\\mu_{year},\\sigma)\\]\n\nGssqAll <- function(par, dat){\n    # dat columns: year, day, count\n    # par is 9 parameters\n    eta <- par[1:4]; # abundance each year, length 4\n    mu <- par[5:8]; # timing  each year, length 4\n    sigma <- par[9]; # spread every yearr, length 1\n    years = unique(dat[,1]) # 1996 to 1999\n    ybar <- numeric(length(dat[,1])) # the predicted, length 21\n    m = 0  # starting index for output vector ybar\n    for (j in 1:length(years)) {  # 4 years: 1996 to 1999\n        k <- which(dat[,1] == years[j]) # find rows in dat for each year\n        for (i in k){ # each observed day in that year\n            m <- m+1 # advance index for output\n            ybar[m]  <- eta[j] * dnorm(dat[m,2],mu[j],sigma)\n            # predicted: abundance times normal(day, timing, spread)\n        }\n    }\n    ssq <- sum( (dat[,3]-ybar)^2) # result of trial values for par\n    return(ssq)\n}\n# par is total abundance 4 years:eta; timing 4 years: mu, and \n# spread for all years: sigma. total 9 parameters.\npar <-  numeric(9)\n# starting guess for search is eta = 2 * sigma * max, mu = 15, sigma=4\n# max for each year is from observed counts.\npar[1:4] <- c(2*4.3*11000, 2*4.3*4100, 2*4.3*700, 2*4.3*4100)\n#  result: 94600 35260  6020 35260\n#  start for yearly timing (mu) is day of observed maximum\npar[5:8] <- c(15,15,19,15)\n# start for spread, sigma, is from preceding fit.\npar[9] <- 4.3\n# the required precision of fit, reltol, is reduced from the default.\nGfit <- optim(par, GssqAll, dat=dat[,1:3], control=list(reltol=0.01) )\npar = Gfit$par; # fitted parameters\npr = round(par, 2) # rounded for printing.\na <- data.frame (Year=1996:1999,eta=pr[1:4],mu=pr[5:8], sigma=pr[9])\nkbl(a)\n\n\n\n \n  \n    Year \n    eta \n    mu \n    sigma \n  \n \n\n  \n    1996 \n    99332.56 \n    13.23 \n    3.69 \n  \n  \n    1997 \n    39586.25 \n    13.62 \n    3.69 \n  \n  \n    1998 \n    6020.14 \n    19.87 \n    3.69 \n  \n  \n    1999 \n    35661.50 \n    13.31 \n    3.69 \n  \n\n\n\n\n# r^2 for overall fit\nSSQ <- sum( (dat[,3] - mean(xa[,2]))^2 ) # SSQ from mean (dumb)\nr2  <-  1- Gfit$value / SSQ\n# print(paste(' r^2 =', round (r2,2) ))\n\nThe resulting fit, with \\(r^2 =\\) 0.99, minimizes SSQ over all years, despite large differences in abundance between years. Perhaps large abundances have a larger effect on the fit than small. To investigate, we determine the fit for each year as separate \\(r^2\\) values.\n\neta <- par[1:4];  mu <- par[5:8]; sigma <- par[9]; \nyear <- unique(dat[,1]) # 1996 to 1999\nnyear <- length(year)   #4 \nyhat <- NULL # will be 21 predicted \n    r2 <- numeric(nyear)\n    for (j in 1:nyear) {\n        k <- which(dat[,1] == year[j]) # index for rows for this year\n        predicted <- eta[j] * dnorm(dat[k,2], mu[j], sigma) # a vector\n        # dat[,2] is day. dat[,3] is count\n        ssq_fit <- sum( (dat[k,3] - predicted      )^2)\n        ssq_raw <- sum( (dat[k,3] - mean(dat[k,3]) )^2)\n        r2[j] <- 1 - ssq_fit / ssq_raw\n        yhat <- c(yhat, predicted) # accumulate and save predicted\n    }\na <- data.frame(Year=year, Abundance =eta, r2=round(r2,2) )\nkbl(a) \n\n\n\n \n  \n    Year \n    Abundance \n    r2 \n  \n \n\n  \n    1996 \n    99332.558 \n    0.99 \n  \n  \n    1997 \n    39586.251 \n    0.80 \n  \n  \n    1998 \n    6020.138 \n    0.80 \n  \n  \n    1999 \n    35661.500 \n    0.93 \n  \n\n\n\n\n\nCompare the estimates of “fish days” from trapezoidal AUC and from fitting Gaussian distributions.\n\na <- data.frame(Year=year, Abundance = round(eta,0),\n     AUC = c(101211, 56010, 9847,45263))\na[,\"Difference(%)\"] <- round( 100*(a$AUC-a$Abundance)/a$Abundance, 2)\nkbl(a)\n\n\n\n \n  \n    Year \n    Abundance \n    AUC \n    Difference(%) \n  \n \n\n  \n    1996 \n    99333 \n    101211 \n    1.89 \n  \n  \n    1997 \n    39586 \n    56010 \n    41.49 \n  \n  \n    1998 \n    6020 \n    9847 \n    63.57 \n  \n  \n    1999 \n    35661 \n    45263 \n    26.93 \n  \n\n\n\n\na1 <- round(mean(abs(a$Difference)),0)\n#print( paste('The mean difference is ', a1, '%.',sep='' )) \n\nThe mean difference in annual estimates of fish days is 33%.’\nThe four Gaussian distributions, and the observed and predicted counts, are plotted in Figure 6 by the following chunk.\n\n# GssqAllPred <- function(par, dat){\n#     # same as GssqAll but returns the predictions. AND smooth curves.\n#     eta <- par[1:4];   mu <- par[5:8]; sigma <- par[9];\n#     years <-  unique(dat[,1]) # 1996 to 1999\n#     nyears <- length(years)\n#     x <- 1:30 # days for smooth\n#     ybar <- numeric(dim(dat)[1] ) # predicted for each day\n#     smooth <- NULL # predicted as smooth curve\n#     m = 0 # row of output, total 21\n#     for (j in 1:nyears) {  # 1 to 4, 1996 to 1999\n#         k <- which(dat[,1] == years[j]) # find rows in a for each year\n#         for (i in k){ # each row in that year\n#             m <- m+1 # row of output\n#             ybar[m]  <- eta[j] * dnorm(dat[m,2],mu[j],sigma)\n#         }\n#         smooth <- c(smooth, eta[j] * dnorm(x,mu[j],sigma)) \n#     }\n#     a <- list(ybar=ybar, smooth=smooth)\n#     return(a)\n# }\n\nx <- c(1:30) # days of September\n# yhat is predicted counts for the days observed\nymax= 1.1e-3 * max(yhat)  # plot as thousands\nSetPar()\nplot(1e-3*yhat ~ dat[,2], xlim=c(1,30), ylim=c(0, ymax), yaxs=\"i\",\n     xlab='Day', ylab=\"Salmon Counts ('000)\" )\npoints(1e-3*dat[,3] ~ dat[,2], pch=1) # observed\nfor (j in 1:4){\n    y  <- eta[j] * dnorm(x, mu[j], sigma) # smooth curve\n    lines(1e-3*y ~ x)\n}\nAxis34()\n\n\n\n\nFigure 6: Four Gaussian curves with the same spread describe the observed salmon abundance. 5 or 6 observations in each year estimate just 2 parameters: abundance and timing."
  },
  {
    "objectID": "posts/welcome/index.html#next-step",
    "href": "posts/welcome/index.html#next-step",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Next Step",
    "text": "Next Step\nSaved for a subsequent post: Determine how to fit the log of the Gaussian to the log of the counts. I discovered a mathematical trick that makes this simple."
  },
  {
    "objectID": "posts/welcome/index.html#down-the-road",
    "href": "posts/welcome/index.html#down-the-road",
    "title": "Spawner Surveys: Not Year By Year.",
    "section": "Down the Road",
    "text": "Down the Road\nThese regressions should be more rigorous, as Bayesian multi-level regression. And what about multiple rivers in the same area that are surveyed in the same years – can the model can be extended to river effects similar to year effects?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Helpful? Examples of Salmon Analysis with R",
    "section": "",
    "text": "news\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2022\n\n\nScott Akenhead\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nanalysis\n\n\nspawner\n\n\nsurvey\n\n\nmulti-level\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2022\n\n\nScott Akenhead\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n123\n\n\nSecond Tag\n\n\n\n\nThis is a test post. In this post, I try out different functionalities\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is my text About this blog."
  },
  {
    "objectID": "posts/new default post/UntitledQMD.html",
    "href": "posts/new default post/UntitledQMD.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod <- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds <- dat %>% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit > 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  }
]